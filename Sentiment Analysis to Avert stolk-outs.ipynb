{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis and Stock-Out Prediction for Modern Contraceptives\n",
    "\n",
    "This Python project analyzes sentiments from news articles about modern contraceptives (e.g., DMPA-SC and IUD) and predicts potential stock-outs based on consumption trends. It uses APIs to fetch news articles and consumption data and leverages sentiment analysis and regression models for predictions.\n",
    "\n",
    "## Features\n",
    "1. Fetches news articles for specified contraceptive methods using NewsAPI.\n",
    "2. Performs sentiment analysis to classify sentiments as Positive, Negative, or Neutral.\n",
    "3. Collects consumption data from an external API and predicts future stock-outs using regression.\n",
    "4. Highlights the method with the most positive sentiment and provides stock-out predictions.\n",
    "\n",
    "## Technologies Used\n",
    "- **Python**: Core programming language.\n",
    "- **Libraries**:\n",
    "  - `requests` for API interaction.\n",
    "  - `pandas` for data handling.\n",
    "  - `TextBlob` for sentiment analysis.\n",
    "  - `scikit-learn` for regression modeling.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### Prerequisites\n",
    "1. Python 3.8 or higher installed.\n",
    "2. API keys for:\n",
    "   - NewsAPI: [Sign up here](https://newsapi.org/).\n",
    "   - Consumption Data API: Access credentials from the relevant provider.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/02/07/5fd2945356dd839974d3a25de8a142dc37293c21315729a41e775b5f3569/textblob-0.18.0.post0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\otieno baker oyugi\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\otieno baker oyugi\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\otieno baker oyugi\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\otieno baker oyugi\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\otieno baker oyugi\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\otieno baker oyugi\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/626.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/626.3 kB 393.8 kB/s eta 0:00:02\n",
      "   ------ ------------------------------- 112.6/626.3 kB 819.2 kB/s eta 0:00:01\n",
      "   ------ ------------------------------- 112.6/626.3 kB 819.2 kB/s eta 0:00:01\n",
      "   ------ ------------------------------- 112.6/626.3 kB 819.2 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 204.8/626.3 kB 734.2 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 245.8/626.3 kB 888.8 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 245.8/626.3 kB 888.8 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 245.8/626.3 kB 888.8 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 245.8/626.3 kB 888.8 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 389.1/626.3 kB 757.8 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 389.1/626.3 kB 757.8 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 501.8/626.3 kB 850.4 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 501.8/626.3 kB 850.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  624.6/626.3 kB 894.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- 626.3/626.3 kB 876.4 kB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Fetch News Articles\n",
    "\n",
    "This function uses the NewsAPI to fetch articles on the modern contraceptives most preferred by Clients and a data range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news(api_key, query, from_date, to_date):\n",
    "    \"\"\"\n",
    "    Fetch news articles related to a query using the NewsAPI.\n",
    "\n",
    "    Parameters:\n",
    "    - api_key (str): API key for NewsAPI.\n",
    "    - query (str): Search term (e.g., contraceptive method).\n",
    "    - from_date (str): Start date for news articles.\n",
    "    - to_date (str): End date for news articles.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of articles with title and description.\n",
    "    \"\"\"\n",
    "    url = f\"https://newsapi.org/v2/everything?q={query}&from={from_date}&to={to_date}&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"articles\", [])\n",
    "    else:\n",
    "        print(f\"Error fetching news: {response.status_code}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Perform Sentiment Analysis\n",
    "\n",
    "Function: Analyze_sentiment\n",
    "\n",
    "This function processes news articles, combines their titles and descriptions, and performs sentiment analysis using TextBlob. Sentiments are the categorized as:\n",
    "\n",
    "         1. Positive(polarity > 0)\n",
    "         2. Negative(Polarity < 0)\n",
    "         3. Neutral(Polarity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(articles):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on news articles and classify sentiments.\n",
    "\n",
    "    Parameters:\n",
    "    - articles (list): List of articles fetched from NewsAPI.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame with sentiment classification (Positive, Negative, Neutral).\n",
    "    \"\"\"\n",
    "    sentiments = []\n",
    "    for article in articles:\n",
    "        text = f\"{article.get('title', '')} {article.get('description', '')}\"\n",
    "        sentiment_score = TextBlob(text).sentiment.polarity\n",
    "        sentiment = (\n",
    "            \"Positive\" if sentiment_score > 0 else \n",
    "            \"Negative\" if sentiment_score < 0 else \n",
    "            \"Neutral\"\n",
    "        )\n",
    "        sentiments.append(sentiment)\n",
    "    return pd.DataFrame(sentiments, columns=[\"Sentiment\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fetch Consumption Data\n",
    "\n",
    "Function: Fetch_Consumption Data\n",
    "\n",
    "This function retrieves consumption data for contraceptive methods from an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_consumption_data(api_endpoint, method_name, api_key):\n",
    "    \"\"\"\n",
    "    Fetch consumption data for a given contraceptive method.\n",
    "\n",
    "    Parameters:\n",
    "    - api_endpoint (str): Endpoint URL for fetching consumption data.\n",
    "    - method_name (str): Contraceptive method name (e.g., DMPA-SC, IUD).\n",
    "    - api_key (str): API key for the consumption data API.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame with consumption data.\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    response = requests.get(f\"{api_endpoint}?method={method_name}\", headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return pd.DataFrame(response.json())\n",
    "    else:\n",
    "        print(f\"Error fetching consumption data: {response.status_code}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Predict Stock-Out\n",
    "Function: Predict_stock_out\n",
    "\n",
    "This function uses linear regression to predict future consumption trends and potention stock-outs based on historical consumption of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stock_out(consumption_data):\n",
    "    \"\"\"\n",
    "    Predict future consumption and potential stock-outs using a simple regression model.\n",
    "\n",
    "    Parameters:\n",
    "    - consumption_data (DataFrame): Historical consumption data.\n",
    "\n",
    "    Returns:\n",
    "    - array: Predicted consumption values for the future.\n",
    "    \"\"\"\n",
    "    consumption_data[\"date\"] = pd.to_datetime(consumption_data[\"date\"])\n",
    "    consumption_data.sort_values(\"date\", inplace=True)\n",
    "    consumption_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Prepare data for the model\n",
    "    consumption_data[\"Index\"] = consumption_data.index\n",
    "    X = consumption_data[[\"Index\"]]\n",
    "    y = consumption_data[\"consumption\"]\n",
    "    \n",
    "    # Train a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict future consumption\n",
    "    future_indices = pd.DataFrame(\n",
    "        {\"Index\": range(len(consumption_data), len(consumption_data) + 12)}\n",
    "    )\n",
    "    future_consumption = model.predict(future_indices)\n",
    "    return future_consumption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Main Execution\n",
    "\n",
    "This is the main block where we:\n",
    "\n",
    "     1. Fetch news articles for specified methods.\n",
    "     2. Perform Sentiment analysis\n",
    "     3. Fetch Consumption data and predict stock-outs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform sentiment analysis and predict stock-outs.\n",
    "    \"\"\"\n",
    "    # API Configuration\n",
    "    NEWS_API_KEY = \"your_news_api_key_here\"\n",
    "    CONSUMPTION_API_ENDPOINT = \"https://example.com/consumption\"\n",
    "    CONSUMPTION_API_KEY = \"your_consumption_api_key_here\"\n",
    "\n",
    "    # Parameters\n",
    "    methods = [\"DMPA-SC\", \"IUD\"]\n",
    "    from_date = \"2024-01-01\"\n",
    "    to_date = \"2024-11-24\"\n",
    "    \n",
    "    # Process each method\n",
    "    sentiments_summary = {}\n",
    "    consumption_predictions = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"Processing {method}...\")\n",
    "        \n",
    "        # Fetch and analyze news articles\n",
    "        articles = fetch_news(NEWS_API_KEY, method, from_date, to_date)\n",
    "        if not articles:\n",
    "            print(f\"No news articles found for {method}\")\n",
    "            continue\n",
    "        \n",
    "        sentiment_df = analyze_sentiment(articles)\n",
    "        sentiments_summary[method] = sentiment_df[\"Sentiment\"].value_counts()\n",
    "        print(f\"Sentiment Summary for {method}:\\n{sentiments_summary[method]}\\n\")\n",
    "        \n",
    "        # Fetch and predict consumption data\n",
    "        consumption_data = fetch_consumption_data(CONSUMPTION_API_ENDPOINT, method, CONSUMPTION_API_KEY)\n",
    "        if not consumption_data.empty:\n",
    "            future_predictions = predict_stock_out(consumption_data)\n",
    "            consumption_predictions[method] = future_predictions\n",
    "        else:\n",
    "            print(f\"No consumption data available for {method}\")\n",
    "    \n",
    "    # Determine the method with the most positive sentiments\n",
    "    most_positive_method = max(sentiments_summary, key=lambda m: sentiments_summary[m].get(\"Positive\", 0))\n",
    "    print(f\"\\nMethod with the most positive sentiments: {most_positive_method}\")\n",
    "    print(f\"\\nFuture Consumption Predictions for {most_positive_method}:\\n{consumption_predictions.get(most_positive_method, 'No predictions available')}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
